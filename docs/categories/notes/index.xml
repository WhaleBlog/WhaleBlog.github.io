<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Notes on WhaleFall's Blog</title><link>https://whaleblog.github.io/categories/notes/</link><description>Recent content in Notes on WhaleFall's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh</language><copyright>&lt;a href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank" rel="noopener">CC BY-NC 4.0&lt;/a></copyright><lastBuildDate>Sun, 01 Sep 2024 13:42:00 +0000</lastBuildDate><atom:link href="https://whaleblog.github.io/categories/notes/index.xml" rel="self" type="application/rss+xml"/><item><title>Virtual Machines</title><link>https://whaleblog.github.io/posts/virtual+machines/</link><pubDate>Sun, 01 Sep 2024 13:42:00 +0000</pubDate><guid>https://whaleblog.github.io/posts/virtual+machines/</guid><description>Host &amp;amp; Guest 虚拟机是对于计算机的模拟，顾名思义。QEMU 可以说是虚拟机的一个例子
在虚拟机架构的最底层，位于硬件之上存在一个 Virtual Machine Monitor（VMM），它取代了标准的操作系统内核。VMM 的工作是模拟多个计算机用来运行 Guest 操作系统。VMM 往上一层是 Guest 空间，对比一个操作系统的用户空间
在 Host 空间运行的是VMM，在 Guest 空间运行的是普通的操作系统。除此之外，在 Guest 空间又可以分为 Guest Supervisor Mode 和 Guest User Mode
我们的目的是让运行在 Guest 中的代码完全不能区分自己是运行在一个虚拟机还是物理机中，因为我们希望能在虚拟机中运行任何操作系统。这意味着对于任何操作系统的行为包括使用硬件的方式，虚拟机都必须提供提供对于硬件的完全相同的模拟，这样任何在真实硬件上能工作的代码，也同样能在虚拟机中工作；我们同样不希望 Guest 从虚拟机中逃逸
但是实际中出于性能的考虑，很难做到完全的模拟。出于效率的考虑，在 VMM 允许的前提下，Linux 某些时候知道自己正在与 VMM 交互，以获得对于设备的高速访问权限。不过实现虚拟机的大致策略还是完全准确的模拟物理服务器
Trap-and-Emulate How to build VMM 一种构建 VMM 的方式是完全通过软件模拟（比如用数组模拟寄存器，用 C 代码模拟指令行为），但是很慢，因为你的 VMM 在解析每一条 Guest 指令的时候，都可能要转换成几十条实际的机器指令，这会导致运行速度慢几个数量级。
相应的，一种广泛使用的策略是在真实的 CPU 上运行 Guest 指令。但是前面说过，我们将 Guest kernel 按照一个 Linux 中的普通用户进程来运行，所以 Guest kernel 现在运行在 User mode，这样在运行 privileged 指令时又会出现问题。但是如果我们蠢到将 Guest kernel 运行在宿主机的 Supervisor mode。那么我们的 Guest kernel 不仅能够修改真实的 Page Table，同时也可以从虚拟机中逃逸，因为它现在可以控制 PTE（Page Table Entry）的内容，并且读写任意的内存内容</description></item><item><title>Meltdown</title><link>https://whaleblog.github.io/posts/meltdown/</link><pubDate>Sat, 31 Aug 2024 21:07:01 +0000</pubDate><guid>https://whaleblog.github.io/posts/meltdown/</guid><description>Meltdown 是一种利用了 CPU 预测执行的攻击手段。如它的名字一样，它”溶解“了用户空间与内核空间的隔离性。详细内容可以访问 https://meltdownattack.com 查看
在这个网站里面还记录了另一个漏洞 Spectre。Intel 的芯片被指出均存在 Meltdown 漏洞, 而 Spectre 漏洞则是危害着所有架构的芯片, 无一幸免。这两个可谓目前为止体系结构历史上影响最大的漏洞了
在有关这个漏洞发布时（2018），大部分操作系统都会将内核内存完整映射到用户空间程序，因为这使得当发生系统调用时，你不用切换 Page Table，也不必清空各种缓存。所以所有的内核 PTE 都会出现在用户程序的 Page Table 中，但是因为这些 PTE 的 PTE_U 比特位没有被设置，用户代码并不能实际的使用内核内存地址
但是 Meltdown 找到了一种方法，可以在没有权限的情况下读取特定地址的比特位。接下来会讲攻击者利用的两个技巧，一个是预测执行，一个是 CPU 缓存
学生提问：所以为了能够攻击，需要先知道内核的虚拟内存地址？
Robert 教授：是的。或许找到内存地址本身就很难，但是你需要假设攻击者有无限的时间和耐心，如果他们在找某个数据，他们或许愿意花费几个月的时间来窃取这个数据。有可能这是某人用来登录银行账号或者邮件用的密码。这意味着攻击者可能需要尝试每一个内核内存地址，以查找任何有价值的数据。
在这个攻守双方的游戏中，我们需要假设攻击者最后可以胜出并拿到内核的虚拟内存地址。所以我们会假设攻击者要么已经知道了一个内核虚拟地址，要么愿意尝试每一个内核虚拟内存地址。
Speculative execution 预测执行是一种用来提升 CPU 性能的技术。假设我们运行如下代码：
r0 = &amp;lt;something&amp;gt; r1 = valid if (r1 == 1) { r2 = *r0 r3 = r2 + 1 } else { r3 = 0 } /* r0, r1, r2, r3 are registers, valid is in RAM */ 任何一个需要从内存中读取数据的 load 指令都会花费 2GHZ CPU 的数百个 CPU cycle，在 r1 获取 valid 值时亦是如此</description></item><item><title>宏内核与微内核</title><link>https://whaleblog.github.io/posts/%E5%AE%8F%E5%86%85%E6%A0%B8%E4%B8%8E%E5%BE%AE%E5%86%85%E6%A0%B8/</link><pubDate>Sat, 31 Aug 2024 11:45:36 +0000</pubDate><guid>https://whaleblog.github.io/posts/%E5%AE%8F%E5%86%85%E6%A0%B8%E4%B8%8E%E5%BE%AE%E5%86%85%E6%A0%B8/</guid><description>完整内容请见：https://mit-public-courses-cn-translatio.gitbook.io/mit6-s081/lec18-os-organization-robert
Monolithic Kernel 宏内核优势 monolithic 的意思是指操作系统内核是一个完成了各种事情的大的程序，我们熟知的 Linux 是由这种方式所构建。通常来说 monolithic kernel 集成了文件系统，内存分配，调度器，虚拟内存系统等一系列复杂的组件，以及许多强大的抽象。这样带来的好处是显而易见的：
这些高度抽象的接口通常是可移植的，可以在各种各样的存储设备上实现文件和目录，而不需要改变代码
可以向应用程序隐藏复杂性。Linux 提供了地址空间的抽象，而不是让程序直接访问 MMU。另外一个例子是，我们可以直接对 fd 调用 read/write，而不需要直接接触文件系统中各个层级
帮助管理共享资源，比如内存与磁盘
因为所有这些功能都在一个程序里面，所以组件之间可以访问彼此的数据结构，进而使得依赖多个组件的工具更容易实现。比如 exec 系统调用，它依赖文件系统，因为它要从磁盘中读取二进制文件并加载到内存中，同时它也依赖内存分配和虚拟内存系统，因为它需要设置好新的进程的地址空间。但是在内核态我们可以没有隔离地访问 inode，proc，pgtbl 等结构体，所以 exec 的中实现是相对简单的
内核的所有代码都以完整的硬件权限（内核都在 Supervisor mode）在运行，这也简化了软件的实现
宏内核劣势 但是其缺点也很明显，这也是为什么其他内核架构，比如微内核，出现的原因，monolithic kernel 并不适用于所有的场景：
它们大且复杂。到目前为止，Linux 的代码量来到了千万行。一个组件可以很方便地与另一个组件交互，这确实使得编程更容易了，但同样意味着内部代码有大量的交互和依赖，以至于看明白代码都有挑战。而且大型的程序与复杂的结构也同样伴随着大量的 Bug 与安全漏洞，如果使用宏内核，这些几乎不可避免
另一个人们不喜欢 monolithic kernel 的原因是，随着时间的推移，它们倾向于发展成拥有所有的功能。Linux 应用在各种场合中，从移动电话到桌面工作站，从笔记本电脑到平板电脑，从服务器到路由器。Linux可以支持这么多设备是极好的，这也使得 Linux 非常的通用。这很好，但是另一方面，通用就意味着慢。对于各种不同的场景都能支持，或许就不能对某些特定场景进行优化。况且很多时候我们根本用不着这么多功能。另外，这也使得完成一些简单的工作需要做很多额外的事情：比如当我们使用 pipe 时，我们需要 buffering，locking，sleep/wakeup，还有 context switching&amp;hellip;&amp;hellip; 但是对于从一个进程移动一个字节到另一个进程来说，这里有大量的内容或许并不是必须的
宏内核还可能因为太大反而削弱了抽象能力。你可以 wait 你自己 fork 的子进程，但不可以等待其他的；你可以 mmap 自己的地址空间，但是为了隔离性不能修改其他的；你可以在磁盘上建一个 B 树，但是读取磁盘时，文件系统不知道这是一个 B 树，这反而不利于效率
还有就是可扩展性，你只能使用内核提供的能力
Micro Kernel 微内核是指一种通用的方法或者概念，并不特指任何特定的产品
微内核的核心就是实现了 IPC（Inter-Process Communication）以及线程和任务的 tiny kernel。所以微内核只提供了进程抽象和通过IPC进程间通信的方式，除此之外别无他物。任何你想要做的事情，例如文件系统，你都会通过一个用户空间进程来实现，完全不会在内核中实现</description></item><item><title>xv6 实验日志 - Lock</title><link>https://whaleblog.github.io/posts/xv6+%E5%AE%9E%E9%AA%8C%E6%97%A5%E5%BF%97+-+lock/</link><pubDate>Mon, 19 Aug 2024 20:07:43 +0000</pubDate><guid>https://whaleblog.github.io/posts/xv6+%E5%AE%9E%E9%AA%8C%E6%97%A5%E5%BF%97+-+lock/</guid><description>刚开始接触这个概念的时候觉得锁更像是通行证一类的东西。问了下 AI，它这么和我解释：
锁（Lock）通常用于确保同一时间只有一个进程或线程能够访问某个资源。当进程或线程想要访问资源时，它必须先获得锁，完成操作后释放锁。这有点像是进入一个房间，你必须拿到钥匙（锁）才能进入，用完后再把钥匙还回去，这样其他人才能使用
锁就是一个对象，就像其他在内核中的对象一样。有一个结构体叫做 lock，它包含了一些字段，这些字段中维护了锁的状态。锁有非常直观的 API：
acquire，接收指向 lock 的指针作为参数。acquire 确保了在任何时间，只会有一个进程能够成功的获取锁
release，也接收指向 lock 的指针作为参数。在同一时间尝试获取锁的其他进程需要等待，直到持有锁的进程对锁调用 release
锁的 acquire 和 release 之间的代码，通常被称为 critical section
之所以被称为 critical section，是因为通常会在这里以原子的方式执行共享数据的更新。所以基本上来说，如果在 acquire 和 release 之间有多条指令，它们要么会一起执行，要么一条也不会执行。所以永远也不可能看到位于 critical section 中的代码，如同在 race condition 中一样在多个 CPU 上交织的执行，所以这样就能避免 race condition
锁序列化了代码的执行。如果两个处理器想要进入到同一个 critical section 中，只会有一个能成功进入，另一个处理器会在第一个处理器从 critical section 中退出之后再进入。所以这里完全没有并行执行
锁的使用完全是由程序员决定的。如果你想要一段代码具备原子性，那么其实是由程序员决定是否增加锁的 acquire 和 release。其次，代码不会自动加锁，程序员自己要确定好是否将锁与数据结构关联，并在适当的位置增加锁的 acquire 和 release
什么时候用锁 一个简单的规则 一个非常保守同时也是非常简单的规则：如果两个进程访问了一个共享的数据结构，并且其中一个进程会更新共享的数据结构，那么就需要对于这个共享的数据结构加锁
但这条规则又很矛盾：这条规则某种程度上来说又太过严格了。如果有两个进程共享一个数据结构，并且其中一个进程会更新这个数据结构，在某些场合不加锁也可以正常工作；而有时候这个规则又太过宽松了。除了共享的数据，在一些其他场合也需要锁，例如对于 printf，如果我们将一个字符串传递给它，xv6 会尝试原子性的将整个字符串输出，而不是与其他进程的 printf 交织输出。尽管这里没有共享的数据结构，但在这里锁仍然很有用处，因为我们想要printf的输出也是序列化的
好吧，这条规则并不完美，但是它已经是一个足够好的指导准则
自动加锁 如果按照刚刚的简单规则，一旦我们有了一个共享的数据结构，任何操作这个共享数据结构都需要获取锁，那么对其进行操作时自动地获取锁即可
但是这样并不行，假如说我要把 ~/dir1/x 文件 mv 到 ~/dir2/y，那么按照这条规则，先对 x 加锁，删除 x，然后释放锁；再对 y 加锁，创建 y，接着释放锁。</description></item><item><title>xv6 实验日志 - Page Table</title><link>https://whaleblog.github.io/posts/xv6+%E5%AE%9E%E9%AA%8C%E6%97%A5%E5%BF%97+-+page+table/</link><pubDate>Thu, 15 Aug 2024 10:56:03 +0000</pubDate><guid>https://whaleblog.github.io/posts/xv6+%E5%AE%9E%E9%AA%8C%E6%97%A5%E5%BF%97+-+page+table/</guid><description>页表 这张图片很好地说明了 xv6 页表机制
其中补充说明几点：
虚拟地址由三部分所组成：EXT（无实际作用，忽略），三级页表的 index，以及物理页的偏移量 offset
每个页表占据一个 PGSIZE 的空间 （4096 bytes），每个页表内有 512 个条目，称为 PTE。每个 PTE 有 64 位，由 PPN 与 Flag 所组成。
对于第一，第二级页表的 PPN，其所指向的是下一级页表的物理地址（由 PPN &amp;laquo; 12 可得）。第三级页表的 PPN 指向的是虚拟地址所映射的物理页的起始地址，加上 va 的 offset 便可得到实际的 pa
satp 寄存器指向第一级页表的物理地址
PTE 中的 flag 在图片的下方有详细的描述
OS 对于地址的映射有绝对的控制权，可以任意地将某个虚拟页映射到某个物理页
虚拟地址到物理地址转换的步骤是由硬件的 MMU 实现的，OS 负责处理页表。但在 xv6 中有 walk() 函数模拟这一点，因为 xv6 通过直接写物理地址来实现内核空间与用户空间的传参
// Return the address of the PTE in page table pagetable // that corresponds to virtual address va.</description></item><item><title>CS61B 学习笔记 - Quicksort</title><link>https://whaleblog.github.io/posts/cs61b+%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0+-+quicksort/</link><pubDate>Tue, 30 Jul 2024 17:57:06 +0000</pubDate><guid>https://whaleblog.github.io/posts/cs61b+%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0+-+quicksort/</guid><description>多年以后，在面对图灵奖时，Tony Hoare 仍会记得一个新手程序员尝试对单词列表进行排序的那个下午（）
另外，这节课的讲师换人了，是他的 secret ruler twin brother
Quicksort 快速排序的想法其实非常简单：选择，分区，然后递归
选择一个元素作为 pivot，一般选择最左边第一个元素
小于等于 pivot 的放在 pivot 的左边，大于 pivot 的放在 pivot 的右边，这样一来 pivot 的位置就确定了
递归地对 pivot 的左边 Quicksort
递归地对 pivot 的右边 Quicksort
快速排序的演示链接在这里
Tony Hoare 将其命名为 Quicksort，而且直到现在，在大多数情况下，快速排序仍然是最快的算法
快速排序的最佳运行时间是 Θ(NlogN)。分区用时 Θ(N)，有 Θ(logN) 层
但是排序一个已经排好的数列，就会触发最坏运行时间 Θ(N2)
但是现实中除非故意为之，几乎不可能遇到这种情况：第一次选择 pivot 便是数组中的最大/最小值概论较小，但并非不可能，不过连续几十次几千次都是如此就几乎不可能出现了。因此，快速排序的时间复杂度往往是 Θ(NlogN)，且一般在 ~2N lnN 次比较后可以完成
下面这张图是对 N = 1000 的数组进行快速排序所需操作次数的分布情况。至于 Θ(N2)，106 都不在图上
虽然快速排序与归并排序都是 O(NlogN)，但是快速排序往往比归并排序要快。（这可能是由于缓存，页命中等更加底层的东西决定的，没有细讲）
Quicksort Flavors 我们怎么做才能避免快速排序的最坏情况呢？那么就让我们来”定制化“一个快速排序吧，从 pivot 选择算法，Partition 算法，到 预处理算法，都有改进地空间。一下是一些改进的思路：
Philosophy 1: Randomness 最坏情况运行时的一些可能原因包括：</description></item><item><title>CS61B 学习笔记 - Basic Sort</title><link>https://whaleblog.github.io/posts/cs61b+%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0+-+basic+sort/</link><pubDate>Tue, 30 Jul 2024 16:03:25 +0000</pubDate><guid>https://whaleblog.github.io/posts/cs61b+%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0+-+basic+sort/</guid><description>In-place Insertion Sort 我们从数组的左边开始，每次选择一个元素进行交换。然后，我们将这个元素交换到它尽可能靠前的位置。数组的前端逐渐变得有序，直到整个数组都被排序。
在逆序数量较少的数组中，插入排序可能是最快的算法。另外，一个不太明显的经验是，插入排序在小数组（小于 15）上非常快，比快速排序与归并排序还快
Selection Sort 选择排序使用以下算法：找到最小的项。把这一项放到前面。重复直到所有项目都固定
在数组中 Θ(N2) 的复杂度真有人会用吗&amp;hellip;&amp;hellip;
Heapsort Naive Heapsort 我们可以另起一个堆，将所有的元素放入到这个堆中，再一个一个把最大值取出来
整体的运行时间是 Θ(NlogN)，毕竟无论是插入元素还是去除最小值都是 O(logN)
但是，为了另起一堆，我们又多花了 Θ(N) 的空间
In-place Heapsort 最大堆删除最大元素时，是将根元素与数组最末尾交换，然后sink(1) 并设置最末尾为 null
而我们完全可以将这最末位的空间利用起来，不通过设置 null 的方式删除原来堆中的最大值，而是就这样将其存在末尾（这也是为什么使用最大而不是最小堆）
我们最开始只要将数组“堆化”，然后以上述方法不断将最大值放在堆的最后，最终我们便得到一个排序好的数组
你可以在这里看到这个算法的演示
Merge Sort 有两个排序好的数组，如何将其合成一个排序好的数组：答案很简单，遍历两个数组，取二者最小，时间复杂度为两数组长度之和
要排序长度为 N 的数组，我们可以将其分成两个长度为 N / 2 的数组并对二者归并排序。N / 2 的数组又可以分成两个 N / 4 的数组，N / 4 又可以分成两个 N / 8&amp;hellip;&amp;hellip; 直到分成两个长度为 1 的数组
这样我们可以得到一颗高度为 Θ(logN) 的树，树的每一层都要进行 Θ(N) 次操作，时间复杂度为 O(NlogN)</description></item><item><title>CS61B 学习笔记 - MST</title><link>https://whaleblog.github.io/posts/cs61b+%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0+-+mst/</link><pubDate>Tue, 30 Jul 2024 14:57:27 +0000</pubDate><guid>https://whaleblog.github.io/posts/cs61b+%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0+-+mst/</guid><description>1. Minimum Spanning Trees A minimum spanning tree (MST) is the lightest set of edges in a graph possible such that all the vertices are connected. Because it is a tree, it must be connected and acyclic. And it is called &amp;ldquo;spanning&amp;rdquo; since all vertices are included.
最小生成树：连接图中所有节点，并使得连接的边和最小的树。
2. Cut Property 我们将一张图随便分为两个部分，一部分标为灰色，另一部分标为白色。
这张图里面一定存在一个最小生成树，这棵树将所有的灰球连接起来，同时将所有的白球连接起来，并且在灰色部分与白色部分的“桥梁”（那些一端是灰球，一端是白球的边）之中，一定有一个“桥梁”属于最小生成树。且这个“桥梁”一定是所有“桥梁”之中，最短的那一条。
这就是所谓的 cut property
We can define a cut as an assignment of a graph’s nodes to two non-empty sets (i.</description></item><item><title>CS61B 学习笔记 - Shortest Paths</title><link>https://whaleblog.github.io/posts/cs61b+%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0+-+shortest+paths/</link><pubDate>Tue, 30 Jul 2024 12:30:43 +0000</pubDate><guid>https://whaleblog.github.io/posts/cs61b+%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0+-+shortest+paths/</guid><description>Dijkstra&amp;rsquo;s Algorithm 还是贴伪代码
def dijkstras(source): # 初始化最小优先队列，存储节点与该节点到起点的最短距离 # 设置起点距离为 0，其他节点距离无限 PQ.add(source, 0) For all other vertices, v, PQ.add(v, infinity) while PQ is not empty: # 出队剩余未操作节点中距离最短的节点 p = PQ.removeSmallest() relax(all edges from p) def relax(edge p,q): if q is visited (i.e., q is not in PQ): return # 若是新路径的距离更短，更新 if distTo[p] + weight(edge) &amp;lt; distTo[q]: distTo[q] = distTo[p] + w edgeTo[q] = p PQ.changePriority(q, distTo[q]) 在图中存在负边的情况下，Dijkstra 算法不能保证正确。这可能有用……但这并不能保证有效。
A* Dijkstra 算法其实像是以起点为中心，向四面八方进行地毯式搜索。但假如我只是搜索武汉到北京的最短路径，我有必要搜索到西藏地区吗？</description></item><item><title>CS61B 学习笔记 - Heap &amp; MinPQ</title><link>https://whaleblog.github.io/posts/cs61b+%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0+-+heap++minpq/</link><pubDate>Tue, 30 Jul 2024 10:08:41 +0000</pubDate><guid>https://whaleblog.github.io/posts/cs61b+%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0+-+heap++minpq/</guid><description>1. Interface 以下是最小优先队列所需实现的方法。在这个数据结构中，我们只关心其最小值。
/** (Min) Priority Queue: Allowing tracking and removal of * the smallest item in a priority queue. */ public interface MinPQ&amp;lt;Item&amp;gt; { /** Adds the item to the priority queue. */ public void add(Item x); /** Returns the smallest item in the priority queue. */ public Item getSmallest(); /** Removes the smallest item from the priority queue. */ public Item removeSmallest(); /** Returns the size of the priority queue.</description></item><item><title>CS61B 学习笔记 - Hash Code</title><link>https://whaleblog.github.io/posts/cs61b+%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0+-+hash+code/</link><pubDate>Tue, 30 Jul 2024 09:13:29 +0000</pubDate><guid>https://whaleblog.github.io/posts/cs61b+%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0+-+hash+code/</guid><description>Valid Hashcodes 有效的哈希码必须拥有一下两个属性：
确定性（Deterministic）：如果两个对象A和B彼此相等（A.equals(B) == true），则它们的hashCode()函数返回相同的哈希码。这也意味着哈希函数不能依赖于在equals()方法中没有反映的对象属性。
比如我们有一个类Dog，其equals方法是：
@Override public boolean equals(Object other) { if (other == this) return true; if (other == null) return false; if (other.getClass() != this.getClass()) return false; Dog that = (Dog) other; return this.breed == that.breed; } 那么我们的`hashCode()`就不能依赖`breed`之外的属性了 另外，这也要求，**当我们重写**`hashCode()`**时，我们也必须同时重写**`equals()`，因为这是我们认为两个对象相等的唯一依据。 一致性（Consistent）：hashCode()函数在同一个对象实例上每次调用时都返回相同的整数。这意味着hashCode()函数必须独立于时间/秒表、随机数生成器或任何在同一个对象实例上多次调用hashCode()函数时不会给出一致哈希码的方法。
请注意，没有要求说不相等的对象应该有不同的哈希函数值，那怕每次只返回 -1，那也是一个有效的哈希码。
Good Hashcodes hashCode()函数必须是有效的。
hashCode()函数的值应该尽可能均匀地分布在整个整数集合上。
hashCode()函数的计算应该相对快速（理想情况下是O(1)的常量时间数学运算）。</description></item><item><title>CS61B 学习笔记 - BST &amp; B-Trees</title><link>https://whaleblog.github.io/posts/cs61b+%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0+-+bst++b-trees/</link><pubDate>Tue, 30 Jul 2024 07:55:29 +0000</pubDate><guid>https://whaleblog.github.io/posts/cs61b+%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0+-+bst++b-trees/</guid><description>我们都知道，二分搜索，比起一个一个查找，有着非常优秀的运行时间。但是对于一个单向链表，这种算法似乎就束手无策了。
但是，如果我们换种思路，从最开始如何形成这个“链表”，也就是数据结构下手的话&amp;hellip;&amp;hellip;二分查找不就没有问题了吗？
1. BST Definitions Tree 由节点和连接这些节点的边组成，任意两个节点之间只有一条路径
Binary Tree 除了上述要求外，还满足二叉属性约束。即，每个节点有0、1或2个子节点
Binary Search Tree 除了上述所有要求外，还满足以下性质：
对于树中的每个节点X：
左子树中的每个键都小于X的键
右子树中的每个键都大于X的键
2. BST Operations find 得益于二叉搜索树的特性，我们可以很简单地使用二分查找
static BST find(BST T, Key sk) { if (T == null) return null; if (sk.equals(T.key)) return T; else if (sk ≺ T.key) return find(T.left, sk); else return find(T.right, sk); } insert 只需注意在插入时也保持左边小，右边大的特性就行
static BST insert(BST T, Key ik) { if (T == null) return new BST(ik); if (ik ≺ T.</description></item><item><title>CS61B 学习笔记 - Disjoint Sets</title><link>https://whaleblog.github.io/posts/cs61b+%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0+-+disjoint+sets/</link><pubDate>Mon, 29 Jul 2024 08:19:40 +0000</pubDate><guid>https://whaleblog.github.io/posts/cs61b+%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0+-+disjoint+sets/</guid><description>1. Interface 对于 Disjoint Sets，我们定义如下接口：
public interface DisjointSets { /** connects two items P and Q */ void connect(int p, int q); /** checks to see if two items are connected */ boolean isConnected(int p, int q); } connect 方法会将两个整数归为同一个集合，isConnected 则用来判断两个整数是否为同一集合
例如，我们有四个元素 A，B，C，D
在调用connect(A, B) 后：
isConnected(A, B) -&amp;gt; true
isConnected(A, C) -&amp;gt; false
然后调用connect(A, D)：
于是有：
isConnected(A, D) -&amp;gt; true
isConnected(A, C) -&amp;gt; false
2. Implements 完整的实现请参照 WeightedQuickUnionUF
2.1 isConnected 我们使用parent数组来表示这样的不相交集。准确来说，使用数组来表示几颗棵树，处在同一棵树的元素，即拥有相同根节点的元素，属于同一个集合</description></item><item><title>在 Matebook E 2022 上安装 Kubuntu18.04</title><link>https://whaleblog.github.io/posts/%E5%A6%82%E6%9E%9C%E4%BD%A0%E6%83%B3%E5%9C%A8+matebook+e+2022+%E4%B8%8A%E4%BD%BF%E7%94%A8+linux/</link><pubDate>Sat, 06 Jul 2024 16:26:00 +0000</pubDate><guid>https://whaleblog.github.io/posts/%E5%A6%82%E6%9E%9C%E4%BD%A0%E6%83%B3%E5%9C%A8+matebook+e+2022+%E4%B8%8A%E4%BD%BF%E7%94%A8+linux/</guid><description>0. 在开始之前 P.S. 这篇博客的内容已过时
这篇博客不牵涉启动盘的制作，磁盘分区以及系统安装的过程（这些内容你大可以 STFW，网络上有很多更加成熟的教程），目的更多在于方便本人重装之后能够快速上手，故而本文的内容比较杂，包括针对该设备的系统设置，常用工具的安装以及简单的美化
在 Matebook E 2022 这台设备上安装 Linux 时会遇到显卡驱动的问题，可以看看这个帖子：Huawei Matebook e 2022 款 Iris Xe 显卡问题。对于我这台机子，在不开安全模式的情况下，屏幕的左右两侧会像地质断层一样上下割裂错位。我尝试了 Arch Linux 和 Ubuntu 24 到 19 的版本，皆会出现上述的情况。只有 Kubuntu 18.04 这个版本才能正常显示
好吧，如果你只是想用这台机器装一个可以使用的 Linux 系统的话，目前我已知最简单的方式，安装 Kubuntu 18.04 吧
后面有佬做到了在这台设备上安装 Arch Linux，并且详细讲述了后续的安装流程，我跟着他的说明成功安装。所以，如果是要在日常中使用的话，就没有必要将时间花在这篇老古董身上了
1. 系统设置 Hardware -&amp;gt; Display and Monitor -&amp;gt; 将窗口拉大后可以看到 Scale Display -&amp;gt; 滑动 Scale 调整至 1.7 或 1.8
Power Management -&amp;gt; Energy Saving -&amp;gt; 自行设置（设备默认省电方案可能会导致系统卡死的情况出现）
如果不小心删除了底部面板：右键桌面 -&amp;gt; Add Panel -&amp;gt; Kubuntu Default Panel</description></item></channel></rss>